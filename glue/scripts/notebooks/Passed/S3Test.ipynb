{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59403f3e-fee2-4c86-9b63-2261a87d10bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized successfully\n",
      "+-----------------+---------------+--------------------+--------------------+-----------+\n",
      "|      customer_id|           name|               email|             address|signup_date|\n",
      "+-----------------+---------------+--------------------+--------------------+-----------+\n",
      "|             5376|    Jaime Weber|  adam81@example.org|98843 Justin Squares|       null|\n",
      "|  West Jayborough|      PA 27422\"|          2021-01-26|                null|       null|\n",
      "|             9429|   Leonard Ruiz|rachel38@example.com|38493 Dougherty K...|       null|\n",
      "| West Thomashaven|      DC 70645\"|          2021-11-01|                null|       null|\n",
      "|             7584| Brittany Perez|  esmith@example.net|30683 Anderson Vista|       null|\n",
      "|    South Brandon|      RI 34383\"|          2020-12-05|                null|       null|\n",
      "|             1781|   Robert Moore|kentkaufman@examp...| 959 Jill Throughway|       null|\n",
      "|       Thomasberg|      RI 27772\"|          2022-04-03|                null|       null|\n",
      "|             3623|    Allison Cox|jonathon36@exampl...|    86897 Cruz Haven|       null|\n",
      "|       East Amber|      FM 65642\"|          2022-01-16|                null|       null|\n",
      "|             1285|Danielle Glover|kellireyes@exampl...|  616 Mcguire Tunnel|       null|\n",
      "|       Port Jared|      IN 55309\"|          2021-11-26|                null|       null|\n",
      "|             6237|   Julie Burton|joseph79@example.com|   143 Brittany Keys|       null|\n",
      "|       New Alicia|      NY 77464\"|          2024-01-07|                null|       null|\n",
      "|             8477|  Anne Anderson|yangadam@example.com|   69005 Marvin Port|       null|\n",
      "|New Nicholasmouth|      KY 94018\"|          2021-03-05|                null|       null|\n",
      "|             6370|   Crystal Carr|kempnancy@example...| 279 Rodriguez Haven|       null|\n",
      "|    Martinezmouth|      TN 21851\"|          2022-09-11|                null|       null|\n",
      "|             3446|    David Munoz|amorrison@example...|11463 Gonzalez Gl...|       null|\n",
      "|      Margaretton|      IL 38076\"|          2024-01-21|                null|       null|\n",
      "+-----------------+---------------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Define parameters in a dictionary\n",
    "parameters = {\n",
    "    'JOB_NAME': 'FullLoadAndCDCProcesserJob',\n",
    "    'RAW_S3_PATH': 's3://ecommerce-data-lake-us-east-1-dev/01_raw/',\n",
    "    'STAGING_S3_PATH': 's3://ecommerce-data-lake-us-east-1-dev/02_staging/',\n",
    "    'PREPROCESSED_S3_PATH': 's3://ecommerce-data-lake-us-east-1-dev/03_preprocessed/',\n",
    "    'MASTER_S3_PATH': 's3://ecommerce-data-lake-us-east-1-dev/04_master/',\n",
    "    'CURATED_S3_PATH': 's3://ecommerce-data-lake-us-east-1-dev/06_curated/',\n",
    "    'TABLE_NAME': 'orders',\n",
    "    'PROCESS_TYPE': 'full_load',\n",
    "    'SOURCE': 'netSuite'\n",
    "}\n",
    "\n",
    "# Mock function to simulate getResolvedOptions\n",
    "def get_resolved_options(args, keys):\n",
    "    return {key: parameters[key] for key in keys}\n",
    "\n",
    "# Mock sys.argv to simulate Glue job arguments\n",
    "sys.argv = [\n",
    "    '--JOB_NAME', parameters['JOB_NAME'],\n",
    "    '--RAW_S3_PATH', parameters['RAW_S3_PATH'],\n",
    "    '--STAGING_S3_PATH', parameters['STAGING_S3_PATH'],\n",
    "    '--PREPROCESSED_S3_PATH', parameters['PREPROCESSED_S3_PATH'],\n",
    "    '--MASTER_S3_PATH', parameters['MASTER_S3_PATH'],\n",
    "    '--CURATED_S3_PATH', parameters['CURATED_S3_PATH'],\n",
    "    '--TABLE_NAME', parameters['TABLE_NAME'],\n",
    "    '--PROCESS_TYPE', parameters['PROCESS_TYPE'],\n",
    "    '--SOURCE', parameters['SOURCE']\n",
    "]\n",
    "\n",
    "# Use the mock get_resolved_options function\n",
    "args = get_resolved_options(sys.argv, [\n",
    "    'JOB_NAME', \n",
    "    'RAW_S3_PATH', \n",
    "    'STAGING_S3_PATH', \n",
    "    'PREPROCESSED_S3_PATH', \n",
    "    'MASTER_S3_PATH',\n",
    "    'CURATED_S3_PATH', \n",
    "    'TABLE_NAME', \n",
    "    'PROCESS_TYPE',\n",
    "    'SOURCE'\n",
    "])\n",
    "\n",
    "# Paths to JAR files\n",
    "hadoop_aws_jar_path = \"/opt/glue/jars/hadoop-aws-3.2.0.jar\"\n",
    "aws_sdk_jar_path = \"/opt/glue/jars/aws-java-sdk-bundle-1.11.375.jar\"\n",
    "\n",
    "# Initialize Spark session with S3 configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars\", \",\".join([hadoop_aws_jar_path, aws_sdk_jar_path])) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"--add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session initialized successfully\")\n",
    "\n",
    "# Read source data\n",
    "source_df = spark.read.format(\"csv\").option(\"header\", \"true\").load('s3a://ecommerce-data-lake-us-east-1-dev/customers.csv')\n",
    "\n",
    "# Show the data\n",
    "source_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0643ef-d240-4e72-8932-d3f00e67601c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
