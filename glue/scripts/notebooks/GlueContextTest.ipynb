{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86abd6e-488d-4c24-bfc1-e726ea81757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3883b5d-5f30-4c9d-8473-07b8f875a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Spark session\n",
    "def get_spark_session(hadoop_aws_jar, aws_sdk_jar):\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"DataLakeETL\") \\\n",
    "        .config(\"spark.jars\", f\"{hadoop_aws_jar},{aws_sdk_jar}\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c99d6f-90da-4c3b-a719-79e203a07043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 00:42:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/29 00:42:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "INFO:__main__:Spark session initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "try:\n",
    "    spark = get_spark_session(\"/opt/glue/jars/hadoop-aws-3.2.0.jar\", \"/opt/glue/jars/aws-java-sdk-bundle-1.11.375.jar\")\n",
    "    logger.info(\"Spark session initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Spark session: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7bf531-cb8d-48e7-a569-2cf8cc5f2427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error initializing Glue context: 'JavaPackage' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Glue context\n",
    "try:\n",
    "    sc = SparkSession.builder.getOrCreate()\n",
    "    glue_context = GlueContext(sc)\n",
    "    logger.info(\"Glue context initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Glue context: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305458cb-39f9-4ae4-9cf2-17f2d5cfd75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Glue context with basic operation\n",
    "try:\n",
    "    glue_context.create_dynamic_frame.from_catalog(database=\"my_database\", table_name=\"my_table\")\n",
    "    logger.info(\"Glue context operation succeeded.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error performing Glue context operation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e47c13-efbc-4886-8c29-42f62bb2dac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011cf5f0-656e-4646-9a67-b6c734e376cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20cc527-f800-4f8d-867f-5b05e75117cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2b7b05-3ebd-4944-ad0d-a326841ababe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Spark session\n",
    "def get_spark_session(hadoop_aws_jar, aws_sdk_jar):\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"DataLakeETL\") \\\n",
    "        .config(\"spark.jars\", f\"{hadoop_aws_jar},{aws_sdk_jar}\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d286e1d1-4d76-44b7-a01b-ead607b6eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Spark session initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "try:\n",
    "    spark = get_spark_session(\"/opt/glue/jars/hadoop-aws-3.2.0.jar\", \"/opt/glue/jars/aws-java-sdk-bundle-1.11.375.jar\")\n",
    "    logger.info(\"Spark session initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Spark session: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a0baa2-8a63-483b-a5a3-4369b97087dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Spark context initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark context\n",
    "try:\n",
    "    sc = spark.sparkContext\n",
    "    logger.info(\"Spark context initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Spark context: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0fea448-e949-438d-bf43-e09f008062cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error initializing Glue context: 'JavaPackage' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Glue context\n",
    "try:\n",
    "    glue_context = GlueContext(sc)\n",
    "    logger.info(\"Glue context initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Glue context: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c8b733-e8cc-4037-8b6f-bc1d9d8a5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error performing Glue context operation: name 'glue_context' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Test Glue context with basic operation\n",
    "try:\n",
    "    glue_context.create_dynamic_frame.from_catalog(database=\"ecommerce_db_dev\", table_name=\"customers\")\n",
    "    logger.info(\"Glue context operation succeeded.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error performing Glue context operation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb61a2a-40e7-4855-937a-2fcb172cac71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
